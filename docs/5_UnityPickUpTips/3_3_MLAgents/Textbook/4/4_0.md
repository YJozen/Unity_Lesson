# 4. 様々な学習方法

 <a href="https://drive.google.com/drive/folders/1AJkScgeqh2AZD4iH7-2QbmGucvFAiv-J" target="_blank">サンプルファイル</a>

<br>

## 1. 学習アルゴリズムの種類

### ・強化学習アルゴリズム:
1. [SAC](4_1.md)  
連続行動を持つ環境に適したオフポリシーのアルゴリズム。  
エージェントが不確実性を管理しながら最適な行動を学ぶプロセスに焦点を当てます。

2. [Discrete](4_2.md)  
離散行動の選択肢があるタスクに適したアルゴリズム。  
例えば、「左」「右」「ジャンプ」のような固定アクションを選ぶ場合に利用します。

### ・強化学習の拡張技術:
3. [セルフプレイ](4_5.md)  
エージェントが自分と対戦し、難易度を段階的に高めて学習する方法。

4. [Curiosity](4_6.md)  
報酬の少ない環境でエージェントが自主的に探索を促進する技法。

5. [模倣学習](4_7.md)  
デモンストレーションに基づきエージェントが行動を学ぶ方法で、動きを模倣する技術。

<br>

## 2. 観察方法・環境設定

### ・観察手法:
6. [VisualObservation](4_3.md)  
視覚情報（画像や映像）を基にした観察。  
エージェントがカメラからの映像を分析し、物体の認識や位置情報を取得する学習を行います。

7. [Raycast Observation](4_4.md)  
特定の方向にレイを飛ばして情報を取得する観察方法。  
距離や衝突物体の情報を用いて、エージェントの空間認識力を高めます。


### ・環境変数:

8. [環境パラメータのランダム化](4_10.md)  
学習中に環境の条件をランダム化し、エージェントが多様なシナリオに適応できるようにする手法。

<br>

## 3. 学習プロセスの強化

### ・メタ学習

9. [LSTM（Long Short-Term Memory）](4_8.md)  
長期的な依存関係を学習するためのリカレントニューラルネットワーク構造。  
例えば、過去の行動の履歴を考慮に入れた決定を行う際に有用です。


### ・学習進行管理:

10. [カリキュラム学習](4_9.md)  
学習難易度を徐々に上げることで、エージェントが段階的に複雑なタスクを習得できるようにする方法。

<br>

[LSTMとカリキュラム学習について](LSTMとカリキュラム学習について.md)

<br>

---

<br>

<br>

[「Branch」や「Buffers」](Branch_Buffers.md)
