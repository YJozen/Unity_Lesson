AR開発ステップ

<br>

### 0. **初期設定**
   - ARKit（iOS）やARCore（Android）のサポートを有効にし、AR Foundationパッケージをインポートします。
   - AR Session、AR Camera、AR Plane Manager、AR Raycast Managerなどのコンポーネントをシーンに配置します。

<br>

<br>

### 1. **アンカー検出 (Anchor Detection)**

- **目的**  
   ARオブジェクトを物理空間に「固定」するために、ARシステムがカメラやセンサーを利用して環境内の平面や物体を「検出」し、アンカー（固定ポイント）を設置します。これにより、仮想オブジェクトが現実空間の特定の位置に継続的に固定され、ユーザーがカメラの視点を変えてもその位置を維持できます。

- **プロセス**  
   - **環境スキャンと平面検出**  
      物理空間をスキャンして、机や床などの平面や壁などの物理的なオブジェクトを検出します。`ARRaycastManager` や `ARPlaneManager` を使用して、ユーザーがカメラをかざした際に、平面や物体の位置を検出します。

   - **使用するクラスと役割**  
     - `ARRaycastManager`:  
       ユーザーが画面上でタッチした位置にレイキャストを行い、そのタッチ位置に対応する現実空間の平面を検出します。これにより、検出した平面に「アンカー」を配置でき、仮想オブジェクトをその位置に固定することが可能です。例えば、ARアプリで家具を配置する場合、ユーザーが指定した場所に家具を固定できます。
       
     - `ARPlaneManager`:  
       環境内で検出された平面を描画し、ユーザーにその平面が検出されたことを視覚的に示します。このクラスによって生成される平面データを利用して、アンカーやオブジェクトの配置を行います。
       
     - **アンカー設置 (`ARAnchor`)**  
       検出された平面やオブジェクトの位置に対して `ARAnchor` を作成します。これにより、仮想オブジェクトがその位置に固定され、安定した表示が可能になります。

<br>

<br>

<img src="images/1_アンカー検出.png" width="90%" alt="" title="">

<br>

<img src="images/12_平面検出.png" width="90%" alt="" title="">

<br>

<br>

> [アンカー検出_実装例](5_1_検出1_サンプルコード1)
>
> [その他の検出例](5_1_検出2_Detection.md)

<br>

   アンカー検出を行うことで、物理空間内の特定の位置に仮想オブジェクトを「永続的」に固定でき、視点が変わってもオブジェクトがその位置を維持します。この仕組みは、ARで現実空間に仮想オブジェクトを自然に配置するための基礎となります。

<br>

<br>

### 2. **ノード設置 (Node Placement)**
   - 検出した位置に仮想オブジェクト（例えば家具やアイテム）を配置します。ユーザーがタッチした位置に物体を動かして配置します。
   - 配置されたオブジェクトは、物理空間の一部として存在するかのように動き、見えるようになります。

   **実装例**:
   - ユーザーが画面をタッチし、その位置に仮想家具などのオブジェクトを配置する処理を実装します。配置するオブジェクトは、アンカーとして設定された位置に配置されます。


   - ユーザーがタッチした位置に仮想オブジェクトを配置します。このオブジェクトを、検出した平面に合わせて位置決めします。


   ノード設置は、ARシーン内で特定の位置にオブジェクト（例えば「ノード」とも呼ばれるターゲットやポイント）を配置することを指します。ノードやオブジェクトは、Unityエディタ上のシーンに直接配置されるだけでなく、ARアプリケーションを通じてユーザーの現実空間に置かれることが目的です。

<br>

<br>

<img src="images/2_ノード設置.png" width="90%" alt="" title="">


<br>

<img src="images/12_平面検出.png" width="90%" alt="" title="">



<br>

<br>




### 3. **画面に投影 (Screen Projection)**
   - 実際にユーザーのデバイス画面上に仮想オブジェクトを表示します。
   - 投影は、物理空間に仮想オブジェクトがどのように見えるかを画面上にリアルタイムで表示することです。

   **実装例**:
   - 画面上のタッチ位置に合わせてオブジェクトを配置します。画面にオブジェクトが「投影」される形となります。


   - ユーザーがタッチした位置に、ARオブジェクトを投影し、物理空間内に配置します。これにより、ユーザーがAR空間内で実際にオブジェクトを見て操作できるようになります。


   こちらは、カメラ越しに現実空間を写した画面上に、バーチャルなオブジェクトが重ねられて表示されることを指します。たとえば、ARアプリを通じてスマートフォン画面を見たときに、現実のテーブルの上にキャラクターや家具が「投影」されているように見えるのがこの「投影」にあたります。

<br>

<br>

<img src="images/3_画面に投影.png" width="90%" alt="" title="">


<br>

<img src="images/13_ノード設置1.png" width="90%" alt="" title="">

<br>

<img src="images/13_ノード設置2.png" width="90%" alt="" title="">

<br>

<br>



### 4. **アプリUI (App UI)**
   - ユーザーがARコンテンツとやり取りするためのインターフェースを作成します。
   - ARコンテンツ自体だけでなく、メニューや操作ボタン、設定などのユーザーインターフェースを追加します。

   **実装例**:
   - メニューを表示したり、UIボタンをタッチしてARのオブジェクトにアクションを起こす機能を追加します。ARオブジェクトに関する設定をユーザーが操作できるようにします。


   - ARのインタラクションに加えて、メニューや設定ボタンを追加します。これにより、ユーザーはARコンテンツとインタラクションしながら操作することができます。

<br>

<br>

<img src="images/4_アプリUI.png" width="90%" alt="" title="">

<br>

<img src="images/14_投影1.png" width="90%" alt="" title="">

<br>

<img src="images/14_投影2.png" width="90%" alt="" title="">

<br>

<img src="images/14_投影3.png" width="90%" alt="" title="">

<br>

<br>


### 5. **追跡 (Tracking)**
   - ユーザーの動きに合わせて、ARオブジェクトが追跡され、位置や回転が変化するようにします。
   - ユーザーがARオブジェクトを動かしたり、カメラを動かした場合でも、そのオブジェクトが物理空間内で適切に追跡され、配置されるようにします。

   **実装例**:
   - オブジェクトを追跡するために、ARオブジェクトの位置情報をリアルタイムで更新します。`ARTrackedObject`や`ARSession`を使って、デバイスの動きに合わせてオブジェクトが移動するようにします。



   - ユーザーのカメラの動きやオブジェクトの動きに基づき、ARオブジェクトが物理空間内で追跡されます。位置や回転を動的に更新し、現実世界の動きに合わせて調整します。





### 6. **最終調整とビルド (Final Adjustments and Build)**
   - 実装が完了したら、ARアプリケーションをテストして調整を行います。最終的なビルドを行い、ターゲットプラットフォームに向けて出力します。
   - デバイスに合わせて最適化やパフォーマンスチューニングを行います。

   **実装例**:
   - 最後に、アプリケーションが実際のAR環境で正しく動作するかを確認し、バグを修正します。その後、iOSやAndroid向けにビルドし、デバイスにインストールしてテストします。


   - 実際のデバイスでテストし、パフォーマンスや動作を確認します。その後、ARアプリをターゲットプラットフォーム（iOS、Android、Web等）向けにビルドします。

